{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83667302",
   "metadata": {},
   "source": [
    "## Convert the model\n",
    "Convert the model to onnx so that we can run this with C++ onnx runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffca753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d.shrestha\\AppData\\Local\\Temp\\ipykernel_3260\\3502888377.py:39: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model successfully converted to D:\\braineye\\models\\age_prediction_0.0.1.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "BASE_DIR = r\"D:\\braineye\"\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = models.mobilenet_v2(weights='DEFAULT')\n",
    "    model = model.to('cpu')\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, 1)\n",
    "    state_dict = torch.load(model_path, weights_only=True, map_location=torch.device('cpu')) \n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 1. Load your trained model\n",
    "model_path = os.path.join(MODEL_DIR, \"age_prediction_0.0.1.pt\")  # path to your model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# 2. If the model was saved using model.state_dict()\n",
    "# Uncomment and use the same architecture as during training\n",
    "# model = models.mobilenet_v2()  # or mobilenet_v3_small(), etc.\n",
    "# model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "# 3. Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# 4. Create a dummy input matching the model’s expected input size\n",
    "# Example for 128x128 RGB image\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device='cpu')\n",
    "\n",
    "# 5. Define output ONNX file name\n",
    "onnx_file = os.path.join(MODEL_DIR, \"age_prediction_0.0.1.onnx\")\n",
    "\n",
    "# 6. Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,                     # model being run\n",
    "    dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "    onnx_file,                 # where to save the model\n",
    "    export_params=True,        # store the trained parameter weights\n",
    "    opset_version=17,          # ONNX version (17 is latest and recommended)\n",
    "    do_constant_folding=True,  # optimize constant expressions\n",
    "    input_names=['input'],     # input tensor name\n",
    "    output_names=['output'],   # output tensor name\n",
    "    dynamic_axes={             # allow dynamic batch size\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ Model successfully converted to {onnx_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
